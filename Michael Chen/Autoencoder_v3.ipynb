{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage import color\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import time\n",
    "import pdb\n",
    "import re\n",
    "from zipfile import ZipFile\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "torch.manual_seed(1117)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(1117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BloodDataset(Dataset):\n",
    "    \"\"\"Blood Cell Images from https://www.kaggle.com/paultimothymooney/blood-cells.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file filename information.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.subfolder = ['EOSINOPHIL/', 'LYMPHOCYTE/', 'MONOCYTE/', 'NEUTROPHIL/']\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sf = self.subfolder[self.data_frame['label'].iloc[idx]]\n",
    "        \n",
    "        img_name = os.path.join(self.root_dir, sf, self.data_frame['filename'].iloc[idx])\n",
    "\n",
    "        image = io.imread(img_name)\n",
    "        \n",
    "        # Added the following line to change image shape from (240, 320, 3) to (3, 240, 320)\n",
    "        #image = np.repeat(image[None,...],3,axis=0)\n",
    "        # Removed the above line, since it is not a clean transpose. Used following line instead.\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        \n",
    "        image = (image - image.mean()) / image.std()\n",
    "            \n",
    "        image_class = self.data_frame['label'].iloc[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        sample = {'x': image, 'y': image_class}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './blood-cells.zip'\n",
    "partial_path = 'dataset2-master/dataset2-master/images/'\n",
    "full_path = './blood-cells' + '/' + partial_path\n",
    "batch_size = 16\n",
    "\n",
    "dataset = {'train': BloodDataset('train.csv', full_path + 'TRAIN/'),\n",
    "           'validate': BloodDataset('validate.csv', full_path + 'TRAIN/')}\n",
    "train_validate_loader = {x: DataLoader(dataset[x], batch_size = batch_size, shuffle = True, num_workers = 0) for x in ['train', 'validate']}\n",
    "test_loader = DataLoader(BloodDataset('test.csv', full_path + 'TEST/'), batch_size = 1, shuffle = True, num_workers = 0)\n",
    "test_simple_loader = DataLoader(BloodDataset('test_simple.csv', full_path + 'TEST_SIMPLE/'), batch_size = 1, shuffle = True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAE(nn.Module):\n",
    "    def __init__(self, input_dim, code_dim, dropout_rate = 0.2):\n",
    "        super(MyAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, code_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(code_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, input_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = dropout_rate)\n",
    "        \n",
    "        self.fc = nn.Linear(code_dim, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x.view(x.shape[0], 1, -1))\n",
    "        decoded = self.decoder(self.dropout(encoded))\n",
    "        out = F.sigmoid(self.dropout(self.fc(encoded)))\n",
    "        \n",
    "        return out, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyAE(3*240*320, 128)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "model.apply(weights_init)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001, weight_decay = 10 ** (-5))\n",
    "lambda_func = lambda epoch: 0.5 ** epoch\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_func)\n",
    "FC_loss = nn.CrossEntropyLoss()\n",
    "AE_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Originally set num_epoch to 50, but the model stabilized ~11 epochs. I was going to set num_epoch to 15, but the model peaked at 15, so I set it to 20.\n",
    "def train_model(model = model, dataloader = train_validate_loader, optimizer = optimizer, scheduler = scheduler, loss_fn = (FC_loss, AE_loss), num_epoch = 20, verbose = True):\n",
    "    acc_dict = {'train':[],'validate':[]}\n",
    "    loss_dict = {'train':[],'validate':[]}\n",
    "    best_loss = 1e5\n",
    "    phases = ['train', 'validate']\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epoch):\n",
    "        print('Epoch: {}/{}'.format(epoch + 1, num_epoch))\n",
    "        \n",
    "        for p in phases:\n",
    "            running_correct = 0\n",
    "            running_loss = 0\n",
    "            running_total = 0\n",
    "            if p == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            for data in dataloader[p]:\n",
    "                optimizer.zero_grad()               \n",
    "                image = torch.tensor(data['x']).to(device, dtype = torch.float)\n",
    "                label = torch.tensor(data['y']).to(device, dtype = torch.long)\n",
    "                # pred refers to class prediction; rep refers to image reproduction\n",
    "                pred, rep = model(image)\n",
    "                # Here is a learning point! I originally used the following code:\n",
    "                #loss = loss_fn[0](pred.squeeze(1), label) + loss_fn[1](rep.squeeze(), image.view(4, -1))\n",
    "                # loss_fn[1] kept giving me a dimension mismatch error.\n",
    "                # Reason: It occurred to me that not every batch will have exactly 4 (due to remainder).\n",
    "                # I changed the .view to state the dimensions more explicitly.\n",
    "                loss = loss_fn[0](pred.squeeze(1), label) + loss_fn[1](rep.view(image.shape[0], 3, -1), image.view(image.shape[0], 3, -1))\n",
    "                _, preds = torch.max(pred.squeeze(), dim = 1)\n",
    "                num_imgs = image.size()[0]\n",
    "                running_correct += torch.sum(preds == label).item()\n",
    "                running_loss += loss.item()*num_imgs\n",
    "                running_total += num_imgs\n",
    "                if p== 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "        \n",
    "            epoch_acc = float(running_correct / running_total)\n",
    "            epoch_loss = float(running_loss / running_total)\n",
    "            \n",
    "            if verbose or (i % 10 == 0):\n",
    "                print('Phase:{}, epoch loss: {:.4f} Acc: {:.4f}'.format(p, epoch_loss, epoch_acc))\n",
    "                \n",
    "            acc_dict[p].append(epoch_acc)\n",
    "            loss_dict[p].append(epoch_loss)\n",
    "            \n",
    "            # Changed following to seek best epoch_loss, not epoch_acc\n",
    "            if p == 'validate':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = model.state_dict()\n",
    "            else:\n",
    "                if scheduler:\n",
    "                    scheduler.step()\n",
    "        \n",
    "        print('-'*10)\n",
    "                    \n",
    "    time_elapsed = time.time() - start_time\n",
    "    print('Training/validation complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, acc_dict, loss_dict\n",
    "\n",
    "# Source: https://datascience.stackexchange.com/questions/37186/early-stopping-on-validation-loss-or-on-accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mc8000/dl4med/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/mc8000/dl4med/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/mc8000/dl4med/lib/python3.6/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.76 GiB (GPU 0; 11.17 GiB total capacity; 10.59 GiB already allocated; 290.81 MiB free; 10.60 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-10a5a17d4bd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-dcf9c7e6e668>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, optimizer, scheduler, loss_fn, num_epoch, verbose)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mepoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_correct\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrunning_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dl4med/lib/python3.6/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dl4med/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.76 GiB (GPU 0; 11.17 GiB total capacity; 10.59 GiB already allocated; 290.81 MiB free; 10.60 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "model, acc_dict, loss_dict = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './MyAE_v3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(loss_dict['train']))\n",
    "plt.plot(x, loss_dict['train'], 'r', label=\"Train Loss\")\n",
    "plt.plot(x, loss_dict['validate'], 'b', label=\"Validation Loss\")\n",
    "plt.title('MyAE_v3 Train/Validation Loss by Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('MyAE_v3_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(acc_dict['train']))\n",
    "plt.plot(x, acc_dict['train'], 'r', label=\"Train Accuracy\")\n",
    "plt.plot(x, acc_dict['validate'], 'b', label=\"Validation Accuracy\")\n",
    "plt.title('MyAE_v3 Train/Validation Accuracy by Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('MyAE_v3_accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    actual = []\n",
    "    \n",
    "    running_total = len(test_loader)\n",
    "    running_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            image = data['x'].to(device, dtype = torch.float)\n",
    "            pred, _ = model(image)\n",
    "            output = softmax(pred.cpu()).view(-1).numpy()\n",
    "            prediction = np.argmax(output)\n",
    "            predictions.append(prediction)\n",
    "            probabilities.append(output)\n",
    "\n",
    "            label = data['y']\n",
    "            actual.append(label)\n",
    "            \n",
    "            running_correct += torch.sum(prediction == label).item()\n",
    "    \n",
    "    probabilities = np.array(probabilities)\n",
    "    accuracy = float(running_correct / running_total)\n",
    "    \n",
    "    return predictions, probabilities, actual, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model = MyAE(3*240*320, 1024, 128)\n",
    "\n",
    "model.load_state_dict(torch.load('./MyAE_v3.pth', map_location = torch.device('cpu')))\n",
    "model.state_dict()\n",
    "model = model.to(device)\n",
    "\n",
    "predictions, probabilities, actual, accuracy = evaluate_model(model, test_loader)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, target_names, title = 'Confusion Matrix', cmap = None, normalize = True):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    print(accuracy, misclass)\n",
    "    \n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "        \n",
    "    plt.figure(figsize = (8, 6))\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation = 45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "        \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "        \n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment = \"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment = \"center\",\n",
    "                     color = \"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.savefig('MyAE_v3_cm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(actual, predictions)\n",
    "target_names = ['Eosinophil', 'Lymphocyte', 'Monocyte', 'Neutrophil']\n",
    "title = 'MyAE_v3 Confusion Matrix'\n",
    "cmap = None\n",
    "normalize = False\n",
    "\n",
    "plot_confusion_matrix(cm, target_names, title, cmap, normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_actual_binarized = np.array(label_binarize(actual, classes = [0, 1, 2, 3], pos_label = True))\n",
    "n_classes = 4\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = metrics.roc_curve(model_actual_binarized[:, i], probabilities[:, i])\n",
    "    roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr[0], tpr[0], 'r', label = 'Eosinophil AUC = %0.2f' % roc_auc[0])\n",
    "plt.plot(fpr[1], tpr[1], 'g', label = 'Lymphocyte AUC = %0.2f' % roc_auc[1])\n",
    "plt.plot(fpr[2], tpr[2], 'b', label = 'Monocyte AUC = %0.2f' % roc_auc[2])\n",
    "plt.plot(fpr[3], tpr[3], 'y', label = 'Neutrophil AUC = %0.2f' % roc_auc[3])\n",
    "plt.title('MyAE_v3 Receiver Operating Characteristic')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.savefig('MyAE_v3_auroc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, simple_accuracy = evaluate_model(model, test_simple_loader)\n",
    "print(simple_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
